{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c5d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "pd.set_option('display.max_rows', 20)\n",
    "#from numpy.polynomial.polynomial import polyfit\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['lines.markersize'] = 4\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler('color', 'brgmyk')\n",
    "#plt.rcParams[\"font.family\"] = \"Times New Roman\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014672c8",
   "metadata": {},
   "source": [
    "## Load data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be5d95-4987-4e40-99e1-bd66b338890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# location of processed data files created as shown in examples in data/code_examples folder\n",
    "n2o_path = Path(\"./data/data_n2o\")\n",
    "o3_path = Path(\"./data/data_o3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gas_files(location, \n",
    "                   altitudes=[68, 46, 32, 22],\n",
    "                   base_paths={'n2o': n2o_path,\n",
    "                               'o3': o3_path},\n",
    "                   has_header=False):\n",
    "    \"\"\"\n",
    "    Load N2O and O3 data files for a given location and pressure altitudes.\n",
    "    \n",
    "    This function assumes:\n",
    "      - Files are stored in subdirectories by altitude (e.g., './n2o/68/').\n",
    "      - Each file is named as \"gas_location_pressure.csv\", for example, \n",
    "        \"n2o_quistococha_68.csv\".\n",
    "      - Each file contains two columns:\n",
    "            1. A date column (formatted like 2018311.0)\n",
    "            2. A gas concentration column.\n",
    "      - The columns are separated by one or more whitespace characters.\n",
    "      - If the file does not have a header row, it assigns column names \"date\" and \"concentration\".\n",
    "    \n",
    "    Parameters:\n",
    "        location (str): The location name (e.g., 'quistococha').\n",
    "        altitudes (list of int, optional): List of pressure altitudes to load. Defaults to [68, 46, 32, 22].\n",
    "        base_paths (dict, optional): Dictionary mapping gas names to their base directories.\n",
    "                                     Defaults to {'n2o': './n2o', 'o3': './o3'}.\n",
    "        has_header (bool, optional): Whether the CSV files include a header row. Defaults to False.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A nested dictionary where the first-level keys are the gas names and the\n",
    "              second-level keys are the pressure altitudes. Each leaf is a pandas DataFrame.\n",
    "              For example, result['n2o'][68] contains the DataFrame for 'n2o_quistococha_68.csv'.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    for gas, folder in base_paths.items():\n",
    "        data[gas] = {}\n",
    "        for pressure in altitudes:\n",
    "            filename = f\"{gas}_{location}_{pressure}.csv\"\n",
    "            # Construct the path assuming files are in a subfolder named by the pressure altitude.\n",
    "            file_path = os.path.join(folder, str(pressure), filename)\n",
    "            try:\n",
    "                if has_header:\n",
    "                    df = pd.read_csv(file_path, sep='\\s+', engine='python')\n",
    "                else:\n",
    "                    # Explicitly assign column names if no header exists.\n",
    "                    df = pd.read_csv(file_path, sep='\\s+', engine='python', header=None, names=[\"date\", \"concentration\"])\n",
    "                data[gas][pressure] = df\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "                data[gas][pressure] = None\n",
    "                \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b0c8f8",
   "metadata": {},
   "source": [
    "## Combine N2O and O3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e0977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all(gas_data):\n",
    "    \"\"\"\n",
    "    For each altitude in the gas_data dictionary, combine the N2O and O3 data by performing\n",
    "    an inner join on the 'date' column. The function assumes that each DataFrame has at least\n",
    "    the columns 'date' and 'concentration'.\n",
    "    \n",
    "    Parameters:\n",
    "        gas_data (dict): A dictionary with keys 'n2o' and 'o3'. Each of these is a dictionary \n",
    "                         keyed by altitude, where the value is a DataFrame.\n",
    "                         \n",
    "    Returns:\n",
    "        dict: A dictionary keyed by altitude. Each value is a combined DataFrame with columns:\n",
    "              'date', 'n2o', and 'o3'.\n",
    "    \"\"\"\n",
    "    combined_data = {}\n",
    "    \n",
    "    # Loop over altitudes (assuming both gases have the same altitude keys)\n",
    "    for altitude in gas_data['n2o']:\n",
    "        df_n2o = gas_data['n2o'][altitude]\n",
    "        df_o3  = gas_data['o3'][altitude]\n",
    "        \n",
    "        if df_n2o is None or df_o3 is None:\n",
    "            print(f\"Skipping altitude {altitude} hPa because one of the data sets is missing.\")\n",
    "            combined_data[altitude] = None\n",
    "            continue\n",
    "        \n",
    "        # Check that both DataFrames have a 'date' column\n",
    "        if 'date' not in df_n2o.columns:\n",
    "            print(f\"Altitude {altitude} hPa: 'date' column missing in N2O data. Columns found: {df_n2o.columns}\")\n",
    "            combined_data[altitude] = None\n",
    "            continue\n",
    "        if 'date' not in df_o3.columns:\n",
    "            print(f\"Altitude {altitude} hPa: 'date' column missing in O3 data. Columns found: {df_o3.columns}\")\n",
    "            combined_data[altitude] = None\n",
    "            continue\n",
    "        \n",
    "        # Merge on 'date' (inner join keeps only rows with shared dates)\n",
    "        combined_df = pd.merge(df_n2o, df_o3, on='date', suffixes=('_n2o', '_o3'))\n",
    "        # Rename columns to be clear\n",
    "        combined_df.rename(columns={'concentration_n2o': 'n2o',\n",
    "                                    'concentration_o3': 'o3'}, inplace=True)\n",
    "        \n",
    "        combined_data[altitude] = combined_df\n",
    "        \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df75dc2c",
   "metadata": {},
   "source": [
    "## Correlations with p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dbca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from internal location names to reader-friendly names.\n",
    "locations_dict = {\n",
    "    'bashkortostan': 'Bashkortostan',\n",
    "    'bozeman': 'Montana',\n",
    "    'brunei': 'Kalimantan',\n",
    "    'california': 'California',\n",
    "    'catalonia': 'Catalonia',\n",
    "    'colombia': 'Colombia',\n",
    "    'estonia': 'Estonia',\n",
    "    'finland': 'Finland',\n",
    "    'florianopolis': 'Santa Catarina',\n",
    "    'florida': 'Florida',\n",
    "    'france': 'France',\n",
    "    'french_guiana': 'French Guiana',\n",
    "    'huntingdon': 'Southern Québec',\n",
    "    'iceland_e': 'Iceland (E)',\n",
    "    'iceland_w': 'Iceland (W)',\n",
    "    'khabarovsk': 'Khabarovsk',\n",
    "    'congo': 'Congo',\n",
    "    'kyrgyzstan': 'Kyrgyzstan',\n",
    "    'mexico': 'Xochimilco, Mexico City',\n",
    "    'morocco': 'Morocco',\n",
    "    'mukhrino': 'Mukhrino',\n",
    "    'myanmar': 'Myanmar',\n",
    "    'nz_n': 'New Zealand (N)',\n",
    "    'nz_s': 'New Zealand (S)',\n",
    "    'pantanal': 'Pantanal',\n",
    "    'quistococha': 'Peruvian Amazon',\n",
    "    'romania': 'Romania',\n",
    "    'taiwan': 'Taiwan',\n",
    "    'tarapoto': 'Tarapoto',\n",
    "    'tasmania': 'Tasmania',\n",
    "    'tierra_del_fuego': 'Tierra del Fuego',\n",
    "    'uganda_e': 'Uganda (E)',\n",
    "    'uganda_n': 'Uganda (N)',\n",
    "    'uganda_s': 'Uganda (S)',\n",
    "    'wales': 'Wales'\n",
    "    # Add more mappings as needed.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effffb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlations_with_p(locations, \n",
    "                                  altitudes=[68, 46, 32, 22],\n",
    "                                  base_paths={'n2o': n2o_path,\n",
    "                                              'o3': o3_path},\n",
    "                                  has_header=False):\n",
    "    \"\"\"\n",
    "    For each location, load the gas data, combine it so that only days with both N₂O and O₃ measurements remain,\n",
    "    and then calculate the Pearson correlation coefficient and p-value for each altitude using scipy.stats.pearsonr.\n",
    "    \n",
    "    Parameters:\n",
    "      - locations (list of str): List of location names used in the file names.\n",
    "      - altitudes (list of int, optional): List of pressure altitudes (default: [68, 46, 32, 22]).\n",
    "      - base_paths (dict, optional): Dictionary mapping gas names to their base directories.\n",
    "      - has_header (bool, optional): Whether the CSV files include a header row.\n",
    "      \n",
    "    Returns:\n",
    "      dict: A nested dictionary with top-level keys as locations. For each location, the inner dictionary\n",
    "            has altitudes as keys and a dictionary with keys 'r' (the correlation coefficient) and 'p' (the p-value)\n",
    "            as values. If the correlation cannot be computed, both are set to None.\n",
    "    \"\"\"\n",
    "    correlations = {}\n",
    "    \n",
    "    for loc in locations:\n",
    "        # Load the data for the given location.\n",
    "        gas_data = load_gas_files(loc, altitudes=altitudes, base_paths=base_paths, has_header=has_header)\n",
    "        # Combine the data to retain only rows with both measurements.\n",
    "        combined_data = combine_all(gas_data)\n",
    "        \n",
    "        correlations[loc] = {}\n",
    "        for altitude in altitudes:\n",
    "            df = combined_data.get(altitude)\n",
    "            if df is not None and len(df) > 1:\n",
    "                try:\n",
    "                    # Compute Pearson correlation and p-value.\n",
    "                    r, p = pearsonr(df['n2o'], df['o3'])\n",
    "                    correlations[loc][altitude] = {'r': r**2, 'p': p}\n",
    "                except Exception as e:\n",
    "                    correlations[loc][altitude] = {'r': None, 'p': None}\n",
    "            else:\n",
    "                correlations[loc][altitude] = {'r': None, 'p': None}\n",
    "                \n",
    "    return correlations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de1314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # List of locations (as used in your file names)\n",
    "    locations = locations_dict.keys()\n",
    "    \n",
    "    # Calculate correlation coefficients for each location and altitude.\n",
    "    corr_results = calculate_correlations_with_p(locations, \n",
    "                                          altitudes=[68, 46, 32, 22],\n",
    "                                          has_header=False)\n",
    "    \n",
    "    # Print the results.\n",
    "    for loc, alt_dict in corr_results.items():\n",
    "        print(f\"\\nCorrelation coefficients for {loc}:\")\n",
    "        for altitude, values in alt_dict.items():\n",
    "            r = values['r']\n",
    "            p = values['p']\n",
    "            if r is not None:\n",
    "                print(f\"  {altitude} hPa: r = {r:.3f}, p = {p:.5f}\")\n",
    "            else:\n",
    "                print(f\"  {altitude} hPa: Not enough data to compute correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a64808",
   "metadata": {},
   "source": [
    "## Scatterplots with trend lines included"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d94956-f56f-4d7a-bf58-85f46241c469",
   "metadata": {},
   "source": [
    "### Function with p-value markings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429c9ab-d46e-4798-88ce-9e23087a8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stars_for_p(p, levels=(0.001, 1e-6)):\n",
    "    if np.isnan(p):\n",
    "        return ''\n",
    "    #if p < levels[2]:\n",
    "    #    return '***'\n",
    "    if p < levels[1]:\n",
    "        return '**'\n",
    "    if p < levels[0]:\n",
    "        return '*'\n",
    "    return ''\n",
    "\n",
    "def plot_scatter_corr(locations, \n",
    "                      display_names=None,\n",
    "                      altitudes=[68, 46, 32, 22],\n",
    "                      base_paths={'n2o': n2o_path,\n",
    "                                  'o3': o3_path},\n",
    "                      has_header=False,\n",
    "                      x_range=None,\n",
    "                      y_range=None,\n",
    "                      save_path=None,\n",
    "                      save_dpi=300,\n",
    "                      colors=None,\n",
    "                      pstar_levels=(0.05, 1e-3, 1e-6)):\n",
    "    \"\"\"\n",
    "    For a list of locations, load and combine the gas data, then create a grid of subplots.\n",
    "    Each column corresponds to a location and each row to an altitude (top row = highest altitude / lowest pressure).\n",
    "    Each subplot shows:\n",
    "      - A scatter plot of N₂O (x-axis) vs. O₃ (y-axis)\n",
    "      - A linear trend line fitted to the data (x values from 0 to 350)\n",
    "      - An annotation with r² and significance stars based on Pearson correlation p-value\n",
    "      - A title showing the altitude (in hPa)\n",
    "    \"\"\"\n",
    "    # Sort altitudes so highest altitude (lowest pressure) is at the top.\n",
    "    sorted_alts = sorted(altitudes)  # e.g., [22, 32, 46, 68]\n",
    "    n_rows = len(sorted_alts)\n",
    "    n_cols = len(locations)\n",
    "    \n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 5, n_rows * 4), sharex=True, sharey=True)\n",
    "    # Handle case n_rows==1 or n_cols==1 so axs is 2D\n",
    "    if n_rows == 1 and n_cols == 1:\n",
    "        axs = np.array([[axs]])\n",
    "    elif n_rows == 1:\n",
    "        axs = axs.reshape(1, -1)\n",
    "    elif n_cols == 1:\n",
    "        axs = axs.reshape(-1, 1)\n",
    "\n",
    "    for col, loc in enumerate(locations):\n",
    "        disp_name = display_names[col] if display_names is not None and col < len(display_names) else loc\n",
    "        col_color = colors[col] if colors is not None and col < len(colors) else None\n",
    "\n",
    "        # Load and combine the data for this location.\n",
    "        gas_data = load_gas_files(loc, altitudes=altitudes, base_paths=base_paths, has_header=has_header)\n",
    "        combined_data = combine_all(gas_data)\n",
    "\n",
    "        # Column header\n",
    "        axs[0, col].annotate(disp_name, xy=(0.5, 1.15), xycoords='axes fraction',\n",
    "                             ha='center', va='center', fontsize=20, fontweight='bold')\n",
    "\n",
    "        for row, alt in enumerate(sorted_alts):\n",
    "            ax = axs[row, col]\n",
    "            df = combined_data.get(alt)\n",
    "\n",
    "            if df is not None and not df.empty and ('n2o' in df.columns and 'o3' in df.columns):\n",
    "                x = df['n2o']\n",
    "                y = df['o3']\n",
    "\n",
    "                # Scatter\n",
    "                ax.scatter(x, y, alpha=0.7, color=col_color)\n",
    "\n",
    "                # Trend line (robust to small issues via try/except)\n",
    "                try:\n",
    "                    m, b = np.polyfit(x.values, y.values, 1)\n",
    "                    x_line = np.linspace(0, 350, 100)\n",
    "                    y_line = m * x_line + b\n",
    "                    ax.plot(x_line, y_line, color=col_color if col_color is not None else 'black',\n",
    "                            lw=2, linestyle='--')\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                # Pearson r, p and stars (clean NaNs first)\n",
    "                mask = x.notna() & y.notna()\n",
    "                xv, yv = x[mask].values, y[mask].values\n",
    "                if xv.size >= 3:\n",
    "                    r, p = pearsonr(xv, yv)\n",
    "                    r2 = r * r\n",
    "                    stars = _stars_for_p(p, levels=pstar_levels)\n",
    "                else:\n",
    "                    r2, p, stars = np.nan, np.nan, ''\n",
    "\n",
    "                # Annotate with r² and significance stars\n",
    "                ax.text(0.05, 0.95, f\"$r^2$ = {r2:.2f}{stars}\",\n",
    "                        transform=ax.transAxes, fontsize=20, weight='bold',\n",
    "                        va='top', bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "                ax.set_title(f\"{alt} hPa\")\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, \"No data\", transform=ax.transAxes,\n",
    "                        ha='center', va='center', fontsize=12)\n",
    "                ax.set_title(f\"{alt} hPa\")\n",
    "\n",
    "            # Axis ranges\n",
    "            if x_range is not None:\n",
    "                ax.set_xlim(x_range)\n",
    "            if y_range is not None:\n",
    "                ax.set_ylim(y_range)\n",
    "\n",
    "            # Labels\n",
    "            if row == n_rows - 1:\n",
    "                ax.set_xlabel(\"N₂O (ppbv)\")\n",
    "            else:\n",
    "                ax.set_xlabel(\"\")\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(\"O₃ (ppmv)\")\n",
    "            else:\n",
    "                ax.set_ylabel(\"\")\n",
    "\n",
    "            ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=save_dpi)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453de37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Areas with similar longitude above the Americas:\n",
    "if __name__ == '__main__':\n",
    "    # Define the list of locations (used in file names).\n",
    "    location_list = ['huntingdon', 'quistococha', 'tierra_del_fuego']\n",
    "    # Define a corresponding list of display names for the subplot headers.\n",
    "    display_list = ['Southern Québec','Peruvian Amazon', 'Tierra del Fuego']\n",
    "    # Optionally define a list of colors for each column.\n",
    "    color_list = ['steelblue', 'darkorange', 'forestgreen']\n",
    "    # Altitudes can be provided in any order; they will be sorted (lowest pressure/highest altitude on top).\n",
    "    alt_list = [68, 46, 32, 22]\n",
    "    \n",
    "    plot_scatter_corr(locations=location_list, display_names=display_list, altitudes=alt_list,\n",
    "                      has_header=False,\n",
    "                      x_range=(0, 350),   # Adjust as needed\n",
    "                      y_range=(0, 8.2),    # Adjust as needed\n",
    "                      save_path=None,\n",
    "                      colors=color_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf010d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Areas with similar longitude above Asia/Oceania:\n",
    "if __name__ == '__main__':\n",
    "    # Define the list of locations (used in file names).\n",
    "    location_list = ['khabarovsk', 'brunei', 'tasmania']\n",
    "    # Define a corresponding list of display names for the subplot headers.\n",
    "    display_list = ['Khabarovsk','Kalimantan', 'Tasmania']\n",
    "    # Optionally define a list of colors for each column.\n",
    "    color_list = ['steelblue', 'darkorange', 'forestgreen']\n",
    "    # Altitudes can be provided in any order; they will be sorted (lowest pressure/highest altitude on top).\n",
    "    alt_list = [68, 46, 32, 22]\n",
    "    \n",
    "    plot_scatter_corr(locations=location_list, display_names=display_list, altitudes=alt_list,\n",
    "                      has_header=False,\n",
    "                      x_range=(0, 350),   # Adjust as needed\n",
    "                      y_range=(0, 8.2),    # Adjust as needed\n",
    "                      save_path=None,\n",
    "                      colors=color_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a9724a-a246-48fb-a3c7-3f2b687f4e66",
   "metadata": {},
   "source": [
    "### Plotting by latitude zone, figures with adjusted layouts also included in supplements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc934017-f4b7-4a70-9fda-5301471d9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_dict = {\n",
    "    \"bashkortostan\": 1,\n",
    "    \"bozeman\": 1,\n",
    "    \"brunei\": 2,\n",
    "    \"california\": 1,\n",
    "    \"catalonia\": 1,\n",
    "    \"colombia\": 2,\n",
    "    \"estonia\": 1,\n",
    "    \"finland\": 1,\n",
    "    \"florianopolis\": 2,\n",
    "    \"florida\": 2,\n",
    "    \"france\": 1,\n",
    "    \"french_guiana\": 2,\n",
    "    \"huntingdon\": 1,\n",
    "    \"iceland_e\": 1,\n",
    "    \"iceland_w\": 1,\n",
    "    \"khabarovsk\": 1,\n",
    "    \"congo\": 2,\n",
    "    \"kyrgyzstan\": 1,\n",
    "    \"mexico\": 2,\n",
    "    \"morocco\": 1,\n",
    "    \"mukhrino\": 1,\n",
    "    \"myanmar\": 2,\n",
    "    \"nz_n\": 3,\n",
    "    \"nz_s\": 3,\n",
    "    \"pantanal\": 2,\n",
    "    \"quistococha\": 2,\n",
    "    \"romania\": 1,\n",
    "    \"taiwan\": 2,\n",
    "    \"tarapoto\": 2,\n",
    "    \"tasmania\": 3,\n",
    "    \"tierra_del_fuego\": 3,\n",
    "    \"uganda_e\": 2,\n",
    "    \"uganda_n\": 2,\n",
    "    \"uganda_s\": 2,\n",
    "    \"wales\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23dc6ba-28ed-4965-9e29-d30f2ba7ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_nh = [k for k, v in zone_dict.items() if v == 1]\n",
    "keys_eq = [k for k, v in zone_dict.items() if v == 2]\n",
    "keys_sh = [k for k, v in zone_dict.items() if v == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81777d1-4704-4725-88fa-c4057df72c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_nh = [locations_dict[k] for k, v in zone_dict.items() if v in {1}]\n",
    "vals_eq = [locations_dict[k] for k, v in zone_dict.items() if v in {2}]\n",
    "vals_sh = [locations_dict[k] for k, v in zone_dict.items() if v in {3}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eee3bc-8137-482c-aacd-8d1bb23f9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_colors(n, name='tab20'):\n",
    "    cmap = plt.get_cmap(name, n)   # discretize into n distinct colors\n",
    "    return [cmap(i) for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee42d3d-3750-4c03-b532-6e292e8d1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_nh = categorical_colors(len(vals_nh), 'tab20b')  # or 'tab20', 'Dark2', etc.\n",
    "colors_eq = categorical_colors(len(vals_eq), 'tab20')\n",
    "colors_sh = categorical_colors(len(vals_sh), 'tab10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de9156-0e33-4374-93b7-99547fcc8732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting all northern hemisphere (NH) study regions\n",
    "if __name__ == '__main__':\n",
    "    # Define the list of locations (used in file names).\n",
    "    location_list = keys_nh\n",
    "    # Define a corresponding list of display names for the subplot headers.\n",
    "    display_list = vals_nh\n",
    "    # Optionally define a list of colors for each column.\n",
    "    color_list = colors_nh\n",
    "    # Altitudes can be provided in any order; they will be sorted (lowest pressure/highest altitude on top).\n",
    "    alt_list = [68, 46, 32, 22]\n",
    "    \n",
    "    plot_scatter_corr(locations=location_list, display_names=display_list, altitudes=alt_list,\n",
    "                      has_header=False,\n",
    "                      x_range=(0, 350),   # Adjust as needed\n",
    "                      y_range=(0, 8.2),    # Adjust as needed\n",
    "                      save_path=None,\n",
    "                     colors=color_list)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667829d1-ce3e-4b46-a314-237d38c6f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting all tropical study regions\n",
    "if __name__ == '__main__':\n",
    "    # Define the list of locations (used in file names).\n",
    "    location_list = keys_eq\n",
    "    # Define a corresponding list of display names for the subplot headers.\n",
    "    display_list = vals_eq\n",
    "    # Optionally define a list of colors for each column.\n",
    "    color_list = colors_eq\n",
    "    # Altitudes can be provided in any order; they will be sorted (lowest pressure/highest altitude on top).\n",
    "    alt_list = [68, 46, 32, 22]\n",
    "    \n",
    "    plot_scatter_corr(locations=location_list, display_names=display_list, altitudes=alt_list,\n",
    "                      has_header=False,\n",
    "                      x_range=(0, 350),   # Adjust as needed\n",
    "                      y_range=(0, 8.2),    # Adjust as needed\n",
    "                      save_path=None,\n",
    "                     colors=color_list)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f608d2ea-8127-4dee-8d5e-6f5d5df8aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting all southern hemisphere (SH) study regions\n",
    "if __name__ == '__main__':\n",
    "    # Define the list of locations (used in file names).\n",
    "    location_list = keys_sh\n",
    "    # Define a corresponding list of display names for the subplot headers.\n",
    "    display_list = vals_sh\n",
    "    # Optionally define a list of colors for each column.\n",
    "    color_list = colors_sh\n",
    "    # Altitudes can be provided in any order; they will be sorted (lowest pressure/highest altitude on top).\n",
    "    alt_list = [68, 46, 32, 22]\n",
    "    \n",
    "    plot_scatter_corr(locations=location_list, display_names=display_list, altitudes=alt_list,\n",
    "                      has_header=False,\n",
    "                      x_range=(0, 350),   # Adjust as needed\n",
    "                      y_range=(0, 8.2),    # Adjust as needed\n",
    "                      save_path=None,\n",
    "                     colors=color_list)\n",
    "                     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
