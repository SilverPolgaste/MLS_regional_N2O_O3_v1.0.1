{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0e5497-20ed-45e2-9490-e792ef2931d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d86d434-b6fa-4563-b13a-dd8676daf851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder containing the CSV files (created by the code as in examples in the data_processing subfolder), repeat for each gas at each pressure altitude\n",
    "input_folder = \"file_path\"\n",
    "output_folder = \"file_path_cleaned\"\n",
    "\n",
    "\n",
    "# Ensure output folder exists\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Function to clean a single CSV file\n",
    "def clean_csv_file(file_path, output_path):\n",
    "    try:\n",
    "        # Read the CSV file as raw text, line by line\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Split each line by commas and manually clean them\n",
    "        cleaned_data = []\n",
    "        max_cols = 0\n",
    "\n",
    "        for line in lines:\n",
    "            # Split each line into a list of fields\n",
    "            row = line.strip().split(',')\n",
    "            cleaned_data.append(row)\n",
    "            max_cols = max(max_cols, len(row))  # Track the maximum number of columns\n",
    "\n",
    "        # Convert the cleaned data to a DataFrame\n",
    "        df = pd.DataFrame(cleaned_data)\n",
    "\n",
    "        # Ensure all rows have the same number of columns (max_cols)\n",
    "        df = df.apply(lambda x: x.append([np.nan] * (max_cols - len(x))) if len(x) < max_cols else x, axis=1)\n",
    "        \n",
    "        # Convert all data to numeric, filling non-numeric fields with NaN\n",
    "        df = df.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "        # Pad with NaN rows if there are fewer than 12 rows\n",
    "        if df.shape[0] < 12:\n",
    "            missing_rows = 12 - df.shape[0]\n",
    "            pad_df = pd.DataFrame(np.nan, index=np.arange(missing_rows), columns=df.columns)\n",
    "            df = pd.concat([df, pad_df], ignore_index=True)\n",
    "\n",
    "        # Save the cleaned file to the output folder\n",
    "        df.to_csv(output_path, header=False, index=False)\n",
    "        print(f\"Cleaned file saved: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "# Loop through all CSV files in the input folder and clean them\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        clean_csv_file(file_path, output_path)\n",
    "\n",
    "print(\"All files cleaned and saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
